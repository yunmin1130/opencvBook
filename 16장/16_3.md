# OpenCV와 딥러닝 활용

## 구글넷 영상 인식

 - 구글넷은 총 22개의 레이어로 구성, 가장 많은 레이어를 사용한 형태
 - 다양한 크기의 커널을 한번에 사용해 영상에서 큰 특징과 작은 특징 모두 추출
 - 구글넷 인식 기능을 사용하려면 다른 딥 러닝 프레임 워크를 이용해 미리 훈련된 모델 파일과 구성 파일 필요

```c++
  
#include "opencv2/opencv.hpp"
#include <iostream>
#include <fstream>

using namespace cv;
using namespace cv::dnn;
using namespace std;

int main(int argc, char* argv[])
{
	// Load an image

	Mat img;

	if (argc < 2)
		img = imread("space_shuttle.jpg", IMREAD_COLOR);
	else
		img = imread(argv[1], IMREAD_COLOR);

	if (img.empty()) {
		cerr << "Image load failed!" << endl;
		return -1;
	}

	// Load network

	Net net = readNet("bvlc_googlenet.caffemodel", "deploy.prototxt");

	if (net.empty()) {
		cerr << "Network load failed!" << endl;
		return -1;
	}

	// Load class names

	ifstream fp("classification_classes_ILSVRC2012.txt");

	if (!fp.is_open()) {
		cerr << "Class file load failed!" << endl;
		return -1;
	}

	vector<String> classNames;
	string name;
	while (!fp.eof()) {
		getline(fp, name);
		if (name.length())
			classNames.push_back(name);
	}

	fp.close();

	// Inference

	Mat inputBlob = blobFromImage(img, 1, Size(224, 224), Scalar(104, 117, 123));
	net.setInput(inputBlob, "data");
	Mat prob = net.forward();

	// Check results & Display

	double maxVal;
	Point maxLoc;
	minMaxLoc(prob, NULL, &maxVal, NULL, &maxLoc);

	String str = format("%s (%4.2lf%%)", classNames[maxLoc.x].c_str(), maxVal * 100);
	putText(img, str, Point(10, 30), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(0, 0, 255));
	imshow("img", img);

	waitKey();
	return 0;
}
```

## SSD 얼굴 검출

 - 특정 객체의 클래스와 위치, 크기 정보를 실시간으로 추출
 - SSD 알고리즘은 원래 다수의 클래스 객체를 검출할 수 있음
 - 300x300 크기의 2차원 BGR 컬러 영상을 사용
 - Scalar(104, 117, 123) 값을 이용

### 카페 이용시
```c++
const String model = "res10_300x300_ssd_iter_140000_fp16.caffemodel";
const String config = "deploy.prototxt";
Net net = readNet(model, config);
```

### 텐서플로 이용시
```c++
const String model = "opencv_face_detector_uint8.pb";
const String config = "opencv_face_detector.pbtxt";
Net net = readNet(model, config);
```

```c++
#include "opencv2/opencv.hpp"
#include <iostream>

using namespace cv;
using namespace cv::dnn;
using namespace std;

const String model = "res10_300x300_ssd_iter_140000_fp16.caffemodel";
const String config = "deploy.prototxt";
//const String model = "opencv_face_detector_uint8.pb";
//const String config = "opencv_face_detector.pbtxt";

int main(void)
{
	VideoCapture cap(0);

	if (!cap.isOpened()) {
		cerr << "Camera open failed!" << endl;
		return -1;
	}

	Net net = readNet(model, config);

	if (net.empty()) {
		cerr << "Net open failed!" << endl;
		return -1;
	}

	Mat frame;
	while (true) {
		cap >> frame;
		if (frame.empty()) 
			break;

		Mat blob = blobFromImage(frame, 1, Size(300, 300), Scalar(104, 177, 123));
		net.setInput(blob);
		Mat res = net.forward();

		Mat detect(res.size[2], res.size[3], CV_32FC1, res.ptr<float>());

		for (int i = 0; i < detect.rows; i++) {
			float confidence = detect.at<float>(i, 2);
			if (confidence < 0.5) 
				break;

			int x1 = cvRound(detect.at<float>(i, 3) * frame.cols);
			int y1 = cvRound(detect.at<float>(i, 4) * frame.rows);
			int x2 = cvRound(detect.at<float>(i, 5) * frame.cols);
			int y2 = cvRound(detect.at<float>(i, 6) * frame.rows);

			rectangle(frame, Rect(Point(x1, y1), Point(x2, y2)), Scalar(0, 255, 0));

			String label = format("Face: %4.3f", confidence);
			putText(frame, label, Point(x1, y1 - 1), FONT_HERSHEY_SIMPLEX, 0.8, Scalar(0, 255, 0));
		}

		imshow("frame", frame);
		if (waitKey(1) == 27) 
			break;
	}

	return 0;
}
```

 - 생성되는 blob 객체는 1x3x300x300 형태의 4차원 행렬
 - 생성되는 res 행렬은 1x1xNx7 크기의 4차원 행렬
 - N은 검출된 얼굴 후보 영역 개수
 - detect 행렬은 Nx7 크기의 2차원 행렬
 - 2번째 열에 얼굴 신뢰도가 저장, 3번부터 6번까지는 얼굴 영역 사각형 정보가 저장